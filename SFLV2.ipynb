{"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPAgkRZWoQ6n6DVbeKLj5CB"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30685,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#=============================================================================\n# SplitfedV2 (SFLV2) learning: ResNet18 on HAM10000\n# HAM10000 dataset: Tschandl, P.: The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions (2018), doi:10.7910/DVN/DBW86T\n\n# We have three versions of our implementations\n# Version1: without using socket and no DP+PixelDP\n# Version2: with using socket but no DP+PixelDP\n# Version3: without using socket but with DP+PixelDP\n\n# This program is Version1: Single program simulation\n# ==============================================================================","metadata":{"id":"4kT41C07vIdE","executionInfo":{"status":"ok","timestamp":1714056665765,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.553284Z","iopub.execute_input":"2024-04-25T16:24:24.553725Z","iopub.status.idle":"2024-04-25T16:24:24.557661Z","shell.execute_reply.started":"2024-04-25T16:24:24.553691Z","shell.execute_reply":"2024-04-25T16:24:24.556974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\nimport math\nimport os.path\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom glob import glob\nfrom pandas import DataFrame\nimport random\nimport numpy as np\nimport os\n\n\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport copy","metadata":{"id":"DXltPPGmvPai","executionInfo":{"status":"ok","timestamp":1714056687439,"user_tz":-330,"elapsed":18432,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.559090Z","iopub.execute_input":"2024-04-25T16:24:24.559352Z","iopub.status.idle":"2024-04-25T16:24:24.574413Z","shell.execute_reply.started":"2024-04-25T16:24:24.559326Z","shell.execute_reply":"2024-04-25T16:24:24.573681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 1234\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.backends.cudnn.deterministic = True\n    print(torch.cuda.get_device_name(0))\n","metadata":{"id":"uZLzZk9uvSKE","executionInfo":{"status":"ok","timestamp":1714056687439,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.575352Z","iopub.execute_input":"2024-04-25T16:24:24.575605Z","iopub.status.idle":"2024-04-25T16:24:24.591101Z","shell.execute_reply.started":"2024-04-25T16:24:24.575580Z","shell.execute_reply":"2024-04-25T16:24:24.590300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#===================================================================\nprogram = \"SFLV2 ResNet18 on HAM10000\"\nprint(f\"---------{program}----------\")              # this is to identify the program in the slurm outputs files\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# To print in color -------test/train of the client side\ndef prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk))\ndef prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk))\n","metadata":{"id":"VJXyEX-KvUfI","executionInfo":{"status":"ok","timestamp":1714056691342,"user_tz":-330,"elapsed":552,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"outputId":"e3f5cb59-81f6-4557-e579-c475e51d18e9","execution":{"iopub.status.busy":"2024-04-25T16:24:24.592816Z","iopub.execute_input":"2024-04-25T16:24:24.593087Z","iopub.status.idle":"2024-04-25T16:24:24.607453Z","shell.execute_reply.started":"2024-04-25T16:24:24.593061Z","shell.execute_reply":"2024-04-25T16:24:24.606598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#===================================================================\n# No. of users\nnum_users = 5\nepochs = 10\nfrac = 1        # participation of clients; if 1 then 100% clients participate in SFLV2\nlr = 0.0001","metadata":{"id":"G6dD5px1vXis","executionInfo":{"status":"ok","timestamp":1714056706557,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.608473Z","iopub.execute_input":"2024-04-25T16:24:24.608736Z","iopub.status.idle":"2024-04-25T16:24:24.618063Z","shell.execute_reply.started":"2024-04-25T16:24:24.608710Z","shell.execute_reply":"2024-04-25T16:24:24.617372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=====================================================================================================\n#                           Client-side Model definition\n#=====================================================================================================\n# Model at client side\nclass ResNet18_client_side(nn.Module):\n    def __init__(self):\n        super(ResNet18_client_side, self).__init__()\n        self.layer1 = nn.Sequential (\n                nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n                nn.BatchNorm2d(64),\n                nn.ReLU (inplace = True),\n                nn.MaxPool2d(kernel_size = 3, stride = 2, padding =1),\n            )\n        self.layer2 = nn.Sequential  (\n                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1, bias = False),\n                nn.BatchNorm2d(64),\n                nn.ReLU (inplace = True),\n                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n                nn.BatchNorm2d(64),\n            )\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n\n    def forward(self, x):\n        resudial1 = F.relu(self.layer1(x))\n        out1 = self.layer2(resudial1)\n        out1 = out1 + resudial1 # adding the resudial inputs -- downsampling not required in this layer\n        resudial2 = F.relu(out1)\n        return resudial2\n\n\nnet_glob_client = ResNet18_client_side()\nif torch.cuda.device_count() > 1:\n    print(\"We use\",torch.cuda.device_count(), \"GPUs\")\n    net_glob_client = nn.DataParallel(net_glob_client)   # to use the multiple GPUs; later we can change this to CPUs only\n\nnet_glob_client.to(device)\nprint(net_glob_client)","metadata":{"id":"dwes-W6KvbLh","executionInfo":{"status":"ok","timestamp":1714056721544,"user_tz":-330,"elapsed":693,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"outputId":"348120da-2299-41ac-ea01-a2ad4ceaa47b","execution":{"iopub.status.busy":"2024-04-25T16:24:24.619273Z","iopub.execute_input":"2024-04-25T16:24:24.619547Z","iopub.status.idle":"2024-04-25T16:24:24.634845Z","shell.execute_reply.started":"2024-04-25T16:24:24.619520Z","shell.execute_reply":"2024-04-25T16:24:24.634124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=====================================================================================================\n#                           Server-side Model definition\n#=====================================================================================================\n# Model at server side\nclass Baseblock(nn.Module):\n    expansion = 1\n    def __init__(self, input_planes, planes, stride = 1, dim_change = None):\n        super(Baseblock, self).__init__()\n        self.conv1 = nn.Conv2d(input_planes, planes, stride =  stride, kernel_size = 3, padding = 1)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, stride = 1, kernel_size = 3, padding = 1)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.dim_change = dim_change\n\n    def forward(self, x):\n        res = x\n        output = F.relu(self.bn1(self.conv1(x)))\n        output = self.bn2(self.conv2(output))\n\n        if self.dim_change is not None:\n            res =self.dim_change(res)\n\n        output += res\n        output = F.relu(output)\n\n        return output\n\n\nclass ResNet18_server_side(nn.Module):\n    def __init__(self, block, num_layers, classes):\n        super(ResNet18_server_side, self).__init__()\n        self.input_planes = 64\n        self.layer3 = nn.Sequential (\n                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n                nn.BatchNorm2d(64),\n                nn.ReLU (inplace = True),\n                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n                nn.BatchNorm2d(64),\n                )\n\n        self.layer4 = self._layer(block, 128, num_layers[0], stride = 2)\n        self.layer5 = self._layer(block, 256, num_layers[1], stride = 2)\n        self.layer6 = self._layer(block, 512, num_layers[2], stride = 2)\n#         self. averagePool = nn.AvgPool2d(kernel_size = 7, stride = 1)\n        self.averagePool = nn.AvgPool2d(kernel_size=2, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n\n    def _layer(self, block, planes, num_layers, stride = 2):\n        dim_change = None\n        if stride != 1 or planes != self.input_planes * block.expansion:\n            dim_change = nn.Sequential(nn.Conv2d(self.input_planes, planes*block.expansion, kernel_size = 1, stride = stride),\n                                       nn.BatchNorm2d(planes*block.expansion))\n        netLayers = []\n        netLayers.append(block(self.input_planes, planes, stride = stride, dim_change = dim_change))\n        self.input_planes = planes * block.expansion\n        for i in range(1, num_layers):\n            netLayers.append(block(self.input_planes, planes))\n            self.input_planes = planes * block.expansion\n\n        return nn.Sequential(*netLayers)\n\n\n    def forward(self, x):\n        out2 = self.layer3(x)\n        out2 = out2 + x          # adding the resudial inputs -- downsampling not required in this layer\n        x3 = F.relu(out2)\n\n        x4 = self. layer4(x3)\n        x5 = self.layer5(x4)\n        x6 = self.layer6(x5)\n\n#         x7 = F.avg_pool2d(x6, 7)\n#         x8 = x7.view(x7.size(0), -1)\n#         y_hat =self.fc(x8)\n        x7 = self.averagePool(x6)\n        x8 = x7.view(x7.size(0), -1)\n        y_hat = self.fc(x8)\n\n        return y_hat\n\nnet_glob_server = ResNet18_server_side(Baseblock, [2,2,2], 7) #7 is my numbr of classes\nif torch.cuda.device_count() > 1:\n    print(\"We use\",torch.cuda.device_count(), \"GPUs\")\n    net_glob_server = nn.DataParallel(net_glob_server)   # to use the multiple GPUs\n\nnet_glob_server.to(device)\nprint(net_glob_server)","metadata":{"id":"GvQa60duvexb","executionInfo":{"status":"ok","timestamp":1714056737982,"user_tz":-330,"elapsed":700,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"outputId":"4e0bcad1-4806-4c2b-db65-b16e0cfa709d","execution":{"iopub.status.busy":"2024-04-25T16:24:24.709721Z","iopub.execute_input":"2024-04-25T16:24:24.710025Z","iopub.status.idle":"2024-04-25T16:24:24.904138Z","shell.execute_reply.started":"2024-04-25T16:24:24.709997Z","shell.execute_reply":"2024-04-25T16:24:24.903437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#===================================================================================\n# For Server Side Loss and Accuracy\nloss_train_collect = []\nacc_train_collect = []\nloss_test_collect = []\nacc_test_collect = []\nbatch_acc_train = []\nbatch_loss_train = []\nbatch_acc_test = []\nbatch_loss_test = []\n\ncriterion = nn.CrossEntropyLoss()\ncount1 = 0\ncount2 = 0","metadata":{"id":"Zm05LhJBvixs","executionInfo":{"status":"ok","timestamp":1714056771124,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.905508Z","iopub.execute_input":"2024-04-25T16:24:24.905759Z","iopub.status.idle":"2024-04-25T16:24:24.910068Z","shell.execute_reply.started":"2024-04-25T16:24:24.905734Z","shell.execute_reply":"2024-04-25T16:24:24.909405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#====================================================================================================\n#                                  Server Side Programs\n#====================================================================================================\n# Federated averaging: FedAvg\ndef FedAvg(w):\n    w_avg = copy.deepcopy(w[0])\n    for k in w_avg.keys():\n        for i in range(1, len(w)):\n            w_avg[k] += w[i][k]\n        w_avg[k] = torch.div(w_avg[k], len(w))\n    return w_avg\n\ndef calculate_accuracy(fx, y):\n    preds = fx.max(1, keepdim=True)[1]\n    correct = preds.eq(y.view_as(preds)).sum()\n    acc = 100.00 *correct.float()/preds.shape[0]\n    return acc\n\n# to print train - test together in each round-- these are made global\nacc_avg_all_user_train = 0\nloss_avg_all_user_train = 0\nloss_train_collect_user = []\nacc_train_collect_user = []\nloss_test_collect_user = []\nacc_test_collect_user = []\n\n\n#client idx collector\nidx_collect = []\nl_epoch_check = False\nfed_check = False\n\n# Server-side function associated with Training\ndef train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch):\n    global net_glob_server, criterion, device, batch_acc_train, batch_loss_train, l_epoch_check, fed_check\n    global loss_train_collect, acc_train_collect, count1, acc_avg_all_user_train, loss_avg_all_user_train, idx_collect\n    global loss_train_collect_user, acc_train_collect_user, lr\n\n    net_glob_server.train()\n    optimizer_server = torch.optim.Adam(net_glob_server.parameters(), lr = lr)\n\n\n    # train and update\n    optimizer_server.zero_grad()\n\n    fx_client = fx_client.to(device)\n    y = y.to(device)\n\n    #---------forward prop-------------\n    fx_server = net_glob_server(fx_client)\n\n    # calculate loss\n    loss = criterion(fx_server, y)\n    # calculate accuracy\n    acc = calculate_accuracy(fx_server, y)\n\n    #--------backward prop--------------\n    loss.backward()\n    dfx_client = fx_client.grad.clone().detach()\n    optimizer_server.step()\n\n    batch_loss_train.append(loss.item())\n    batch_acc_train.append(acc.item())\n\n    # server-side model net_glob_server is global so it is updated automatically in each pass to this function\n\n    # count1: to track the completion of the local batch associated with one client\n    count1 += 1\n    if count1 == len_batch:\n        acc_avg_train = sum(batch_acc_train)/len(batch_acc_train)           # it has accuracy for one batch\n        loss_avg_train = sum(batch_loss_train)/len(batch_loss_train)\n\n        batch_acc_train = []\n        batch_loss_train = []\n        count1 = 0\n\n        prRed('Client{} Train => Local Epoch: {} \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, l_epoch_count, acc_avg_train, loss_avg_train))\n\n\n        # If one local epoch is completed, after this a new client will come\n        if l_epoch_count == l_epoch-1:\n\n            l_epoch_check = True                # to evaluate_server function - to check local epoch has completed or not\n\n            # we store the last accuracy in the last batch of the epoch and it is not the average of all local epochs\n            # this is because we work on the last trained model and its accuracy (not earlier cases)\n\n            #print(\"accuracy = \", acc_avg_train)\n            acc_avg_train_all = acc_avg_train\n            loss_avg_train_all = loss_avg_train\n\n            # accumulate accuracy and loss for each new user\n            loss_train_collect_user.append(loss_avg_train_all)\n            acc_train_collect_user.append(acc_avg_train_all)\n\n            # collect the id of each new user\n            if idx not in idx_collect:\n                idx_collect.append(idx)\n                #print(idx_collect)\n\n        # This is to check if all users are served for one round --------------------\n        if len(idx_collect) == num_users:\n            fed_check = True                                                  # to evaluate_server function  - to check fed check has hitted\n            # all users served for one round ------------------------- output print and update is done in evaluate_server()\n            # for nicer display\n\n            idx_collect = []\n\n            acc_avg_all_user_train = sum(acc_train_collect_user)/len(acc_train_collect_user)\n            loss_avg_all_user_train = sum(loss_train_collect_user)/len(loss_train_collect_user)\n\n            loss_train_collect.append(loss_avg_all_user_train)\n            acc_train_collect.append(acc_avg_all_user_train)\n\n            acc_train_collect_user = []\n            loss_train_collect_user = []\n\n    # send gradients to the client\n    return dfx_client\n\n# Server-side functions associated with Testing\ndef evaluate_server(fx_client, y, idx, len_batch, ell):\n    global net_glob_server, criterion, batch_acc_test, batch_loss_test\n    global loss_test_collect, acc_test_collect, count2, num_users, acc_avg_train_all, loss_avg_train_all, l_epoch_check, fed_check\n    global loss_test_collect_user, acc_test_collect_user, acc_avg_all_user_train, loss_avg_all_user_train\n\n    net_glob_server.eval()\n\n    with torch.no_grad():\n        fx_client = fx_client.to(device)\n        y = y.to(device)\n        #---------forward prop-------------\n        fx_server = net_glob_server(fx_client)\n\n        # calculate loss\n        loss = criterion(fx_server, y)\n        # calculate accuracy\n        acc = calculate_accuracy(fx_server, y)\n\n\n        batch_loss_test.append(loss.item())\n        batch_acc_test.append(acc.item())\n\n\n        count2 += 1\n        if count2 == len_batch:\n            acc_avg_test = sum(batch_acc_test)/len(batch_acc_test)\n            loss_avg_test = sum(batch_loss_test)/len(batch_loss_test)\n\n            batch_acc_test = []\n            batch_loss_test = []\n            count2 = 0\n\n            prGreen('Client{} Test =>                   \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, acc_avg_test, loss_avg_test))\n\n            # if a local epoch is completed\n            if l_epoch_check:\n                l_epoch_check = False\n\n                # Store the last accuracy and loss\n                acc_avg_test_all = acc_avg_test\n                loss_avg_test_all = loss_avg_test\n\n                loss_test_collect_user.append(loss_avg_test_all)\n                acc_test_collect_user.append(acc_avg_test_all)\n\n            # if all users are served for one round ----------\n            if fed_check:\n                fed_check = False\n\n                acc_avg_all_user = sum(acc_test_collect_user)/len(acc_test_collect_user)\n                loss_avg_all_user = sum(loss_test_collect_user)/len(loss_test_collect_user)\n\n                loss_test_collect.append(loss_avg_all_user)\n                acc_test_collect.append(acc_avg_all_user)\n                acc_test_collect_user = []\n                loss_test_collect_user= []\n\n                print(\"====================== SERVER V1==========================\")\n                print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user_train, loss_avg_all_user_train))\n                print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user, loss_avg_all_user))\n                print(\"==========================================================\")\n\n    return\n","metadata":{"id":"5sjadyd2vq5C","executionInfo":{"status":"ok","timestamp":1714056772688,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.911018Z","iopub.execute_input":"2024-04-25T16:24:24.911269Z","iopub.status.idle":"2024-04-25T16:24:24.929032Z","shell.execute_reply.started":"2024-04-25T16:24:24.911246Z","shell.execute_reply":"2024-04-25T16:24:24.928375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#==============================================================================================================\n#                                       Clients Side Program\n#==============================================================================================================\nclass DatasetSplit(Dataset):\n    def __init__(self, dataset, idxs):\n        self.dataset = dataset\n        self.idxs = list(idxs)\n\n    def __len__(self):\n        return len(self.idxs)\n\n    def __getitem__(self, item):\n        image, label = self.dataset[self.idxs[item]]\n        return image, label\n\n# Client-side functions associated with Training and Testing\nclass Client(object):\n    def __init__(self, net_client_model, idx, lr, device, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n        self.idx = idx\n        self.device = device\n        self.lr = lr\n        self.local_ep = 1\n        #self.selected_clients = []\n        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = 256, shuffle = True)\n        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = 256, shuffle = True)\n\n\n    def train(self, net):\n        net.train()\n        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr)\n\n        for iter in range(self.local_ep):\n            len_batch = len(self.ldr_train)\n            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n                images, labels = images.to(self.device), labels.to(self.device)\n                optimizer_client.zero_grad()\n                #---------forward prop-------------\n                fx = net(images)\n                client_fx = fx.clone().detach().requires_grad_(True)\n\n                # Sending activations to server and receiving gradients from server\n                dfx = train_server(client_fx, labels, iter, self.local_ep, self.idx, len_batch)\n\n                #--------backward prop -------------\n                fx.backward(dfx)\n                optimizer_client.step()\n\n\n            #prRed('Client{} Train => Epoch: {}'.format(self.idx, ell))\n\n        return net.state_dict()\n\n    def evaluate(self, net, ell):\n        net.eval()\n\n        with torch.no_grad():\n            len_batch = len(self.ldr_test)\n            for batch_idx, (images, labels) in enumerate(self.ldr_test):\n                images, labels = images.to(self.device), labels.to(self.device)\n                #---------forward prop-------------\n                fx = net(images)\n\n                # Sending activations to server\n                evaluate_server(fx, labels, self.idx, len_batch, ell)\n\n            #prRed('Client{} Test => Epoch: {}'.format(self.idx, ell))\n\n        return","metadata":{"id":"0reKQhAzvrYF","executionInfo":{"status":"ok","timestamp":1714056787116,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.930133Z","iopub.execute_input":"2024-04-25T16:24:24.930355Z","iopub.status.idle":"2024-04-25T16:24:24.945044Z","shell.execute_reply.started":"2024-04-25T16:24:24.930333Z","shell.execute_reply":"2024-04-25T16:24:24.944495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=====================================================================================================\n# dataset_iid() will create a dictionary to collect the indices of the data samples randomly for each client\n# IID HAM10000 datasets will be created based on this\ndef dataset_iid(dataset, num_users):\n\n    num_items = int(len(dataset)/num_users)\n    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n    for i in range(num_users):\n        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n        all_idxs = list(set(all_idxs) - dict_users[i])\n    return dict_users","metadata":{"id":"ZIhYj_7YvuiB","executionInfo":{"status":"ok","timestamp":1714056795860,"user_tz":-330,"elapsed":545,"user":{"displayName":"Vedant Brahmbhatt","userId":"10731296993634284469"}},"execution":{"iopub.status.busy":"2024-04-25T16:24:24.946674Z","iopub.execute_input":"2024-04-25T16:24:24.946896Z","iopub.status.idle":"2024-04-25T16:24:24.960235Z","shell.execute_reply.started":"2024-04-25T16:24:24.946873Z","shell.execute_reply":"2024-04-25T16:24:24.959630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n#                         Data loading\n#=============================================================================\ndf = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\nprint(df.head())\n\n\nlesion_type = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\n\n# merging both folders of HAM1000 dataset -- part1 and part2 -- into a single directory\nimageid_path = {os.path.splitext(os.path.basename(x))[0]: x\n                for x in glob(os.path.join(\"/kaggle/input/skin-cancer-mnist-ham10000\", '*', '*.jpg'))}\n\n\n#print(\"path---------------------------------------\", imageid_path.get)\ndf['path'] = df['image_id'].map(imageid_path.get)\ndf['cell_type'] = df['dx'].map(lesion_type.get)\ndf['target'] = pd.Categorical(df['cell_type']).codes\nprint(df['cell_type'].value_counts())\nprint(df['target'].value_counts())","metadata":{"id":"tlqv8Yszvw7p","execution":{"iopub.status.busy":"2024-04-25T16:24:24.961057Z","iopub.execute_input":"2024-04-25T16:24:24.961266Z","iopub.status.idle":"2024-04-25T16:24:25.077359Z","shell.execute_reply.started":"2024-04-25T16:24:24.961245Z","shell.execute_reply":"2024-04-25T16:24:25.076759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#==============================================================\n# Custom dataset prepration to Pytorch format\nclass SkinData(Dataset):\n    def __init__(self, df, transform = None):\n\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n\n        return len(self.df)\n\n    def __getitem__(self, index):\n\n        X = Image.open(self.df['path'][index]).resize((64, 64))\n        y = torch.tensor(int(self.df['target'][index]))\n\n        if self.transform:\n            X = self.transform(X)\n\n        return X, y","metadata":{"id":"f9zFXu7yv01P","execution":{"iopub.status.busy":"2024-04-25T16:24:25.078355Z","iopub.execute_input":"2024-04-25T16:24:25.078675Z","iopub.status.idle":"2024-04-25T16:24:25.084047Z","shell.execute_reply.started":"2024-04-25T16:24:25.078639Z","shell.execute_reply":"2024-04-25T16:24:25.083431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n# Train-test split\ntrain, test = train_test_split(df, test_size = 0.1)\n\ntrain = train.reset_index()\ntest = test.reset_index()\n","metadata":{"id":"XY9OxKaTv3lG","execution":{"iopub.status.busy":"2024-04-25T16:24:25.084955Z","iopub.execute_input":"2024-04-25T16:24:25.085209Z","iopub.status.idle":"2024-04-25T16:24:25.099162Z","shell.execute_reply.started":"2024-04-25T16:24:25.085183Z","shell.execute_reply":"2024-04-25T16:24:25.098445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n#                         Data preprocessing\n#=============================================================================\n# Data preprocessing: Transformation\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n                        transforms.RandomVerticalFlip(),\n                        transforms.Pad(3),\n                        transforms.RandomRotation(10),\n                        transforms.CenterCrop(64),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean = mean, std = std)\n                        ])\n\ntest_transforms = transforms.Compose([\n                        transforms.Pad(3),\n                        transforms.CenterCrop(64),\n                        transforms.ToTensor(),\n                        transforms.Normalize(mean = mean, std = std)\n                        ])\n\n\n# With augmentation\ndataset_train = SkinData(train, transform = train_transforms)\ndataset_test = SkinData(test, transform = test_transforms)\n\n#----------------------------------------------------------------\ndict_users = dataset_iid(dataset_train, num_users)\ndict_users_test = dataset_iid(dataset_test, num_users)","metadata":{"id":"INLfRHUJv5qe","execution":{"iopub.status.busy":"2024-04-25T16:24:25.100124Z","iopub.execute_input":"2024-04-25T16:24:25.100376Z","iopub.status.idle":"2024-04-25T16:24:25.113981Z","shell.execute_reply.started":"2024-04-25T16:24:25.100352Z","shell.execute_reply":"2024-04-25T16:24:25.113245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#------------ Training And Testing -----------------\nnet_glob_client.train()\n#copy weights\nw_glob_client = net_glob_client.state_dict()\n\n# Federation takes place after certain local epochs in train() client-side\n# this epoch is global epoch, also known as rounds\nfor iter in range(epochs):\n    m = max(int(frac * num_users), 1)\n    idxs_users = np.random.choice(range(num_users), m, replace = False)\n    w_locals_client = []\n\n    for idx in idxs_users:\n        local = Client(net_glob_client, idx, lr, device, dataset_train = dataset_train, dataset_test = dataset_test, idxs = dict_users[idx], idxs_test = dict_users_test[idx])\n        # Training ------------------\n        w_client = local.train(net = copy.deepcopy(net_glob_client).to(device))\n        w_locals_client.append(copy.deepcopy(w_client))\n\n        # Testing -------------------\n        local.evaluate(net = copy.deepcopy(net_glob_client).to(device), ell= iter)\n\n\n    # Ater serving all clients for its local epochs------------\n    # Federation process at Client-Side------------------------\n    print(\"------------------------------------------------------------\")\n    print(\"------ Fed Server: Federation process at Client-Side -------\")\n    print(\"------------------------------------------------------------\")\n    w_glob_client = FedAvg(w_locals_client)\n\n    # Update client-side global model\n    net_glob_client.load_state_dict(w_glob_client)","metadata":{"id":"DoV8O1swv-WO","execution":{"iopub.status.busy":"2024-04-25T16:24:25.115090Z","iopub.execute_input":"2024-04-25T16:24:25.115351Z","iopub.status.idle":"2024-04-25T16:42:23.907915Z","shell.execute_reply.started":"2024-04-25T16:24:25.115325Z","shell.execute_reply":"2024-04-25T16:42:23.907079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#===================================================================================\n\nprint(\"Training and Evaluation completed!\")\n\n#===============================================================================","metadata":{"id":"yufYYiqlwA8-","execution":{"iopub.status.busy":"2024-04-25T16:42:23.909119Z","iopub.execute_input":"2024-04-25T16:42:23.909433Z","iopub.status.idle":"2024-04-25T16:42:23.913865Z","shell.execute_reply.started":"2024-04-25T16:42:23.909385Z","shell.execute_reply":"2024-04-25T16:42:23.913145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T16:48:54.890412Z","iopub.execute_input":"2024-04-25T16:48:54.890780Z","iopub.status.idle":"2024-04-25T16:48:59.901738Z","shell.execute_reply.started":"2024-04-25T16:48:54.890752Z","shell.execute_reply":"2024-04-25T16:48:59.900679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save output data to .excel file (we use for comparision plots)\n\nround_process = [i for i in range(1, len(acc_train_collect)+1)]\ndf = DataFrame({'round': round_process,'acc_train':acc_train_collect, 'acc_test':acc_test_collect})\nfile_name = program+\".xlsx\"\ndf.to_excel(file_name, sheet_name= \"v1_test\", index = False)\n\n#=============================================================================\n#                         Program Completed\n#=============================================================================","metadata":{"id":"AnJJBA5dwDan","execution":{"iopub.status.busy":"2024-04-25T16:49:03.764072Z","iopub.execute_input":"2024-04-25T16:49:03.764509Z","iopub.status.idle":"2024-04-25T16:49:03.916075Z","shell.execute_reply.started":"2024-04-25T16:49:03.764471Z","shell.execute_reply":"2024-04-25T16:49:03.915289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}