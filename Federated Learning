{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30700,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#===========================================================\n# Federated learning: ResNet18 on HAM10000\n# HAM10000 dataset: Tschandl, P.: The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions (2018), doi:10.7910/DVN/DBW86T\n\n# We have three versions of our implementations\n# Version1: without using socket and no DP+PixelDP\n# Version2: with using socket but no DP+PixelDP\n# Version3: without using socket but with DP+PixelDP\n\n# This program is Version1: Single program simulation \n# ===========================================================\nimport torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom pandas import DataFrame\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom glob import glob \nimport math\nimport random\nimport numpy as np\nimport os\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport copy\n\n\nSEED = 1234\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.backends.cudnn.deterministic = True\n    print(torch.cuda.get_device_name(0))    \n\n\n#===================================================================  \nprogram = \"FL ResNet18 on HAM10000\"\nprint(f\"---------{program}----------\")              # this is to identify the program in the slurm outputs files\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# To print in color during test/train \ndef prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk)) \ndef prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk))    \n\n\n#===================================================================\n# No. of users\nnum_users = 5\nepochs = 10\nfrac = 1\nlr = 0.0001\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:53.996919Z","iopub.execute_input":"2024-05-03T22:43:53.997886Z","iopub.status.idle":"2024-05-03T22:43:58.060136Z","shell.execute_reply.started":"2024-05-03T22:43:53.997837Z","shell.execute_reply":"2024-05-03T22:43:58.059187Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Tesla T4\n---------FL ResNet18 on HAM10000----------\n","output_type":"stream"}]},{"cell_type":"code","source":"#==============================================================================================================\n#                                  Client Side Program \n#==============================================================================================================\nclass DatasetSplit(Dataset):\n    def __init__(self, dataset, idxs):\n        self.dataset = dataset\n        self.idxs = list(idxs)\n\n    def __len__(self):\n        return len(self.idxs)\n\n    def __getitem__(self, item):\n        image, label = self.dataset[self.idxs[item]]\n        return image, label\n\n# Client-side functions associated with Training and Testing\nclass LocalUpdate(object):\n    def __init__(self, idx, lr, device, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n        self.idx = idx\n        self.device = device\n        self.lr = lr\n        self.local_ep = 1\n        self.loss_func = nn.CrossEntropyLoss()\n        self.selected_clients = []\n        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = 256, shuffle = True)\n        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = 256, shuffle = True)\n\n    def train(self, net):\n        net.train()\n        # train and update\n        #optimizer = torch.optim.SGD(net.parameters(), lr = self.lr, momentum = 0.5)\n        optimizer = torch.optim.Adam(net.parameters(), lr = self.lr)\n        \n        epoch_acc = []\n        epoch_loss = []\n        for iter in range(self.local_ep):\n            batch_acc = []\n            batch_loss = []\n            \n            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n                images, labels = images.to(self.device), labels.to(self.device)\n                optimizer.zero_grad()\n                #---------forward prop-------------\n                fx = net(images)\n                \n                # calculate loss\n                loss = self.loss_func(fx, labels)\n                # calculate accuracy\n                acc = calculate_accuracy(fx, labels)\n                \n                #--------backward prop--------------\n                loss.backward()\n                optimizer.step()\n                              \n                batch_loss.append(loss.item())\n                batch_acc.append(acc.item())\n            \n            \n            prRed('Client{} Train => Local Epoch: {}  \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(self.idx,\n                        iter, acc.item(), loss.item()))\n            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n            epoch_acc.append(sum(batch_acc)/len(batch_acc))\n        return net.state_dict(), sum(epoch_loss) / len(epoch_loss), sum(epoch_acc) / len(epoch_acc)\n    \n    def evaluate(self, net):\n        net.eval()\n           \n        epoch_acc = []\n        epoch_loss = []\n        with torch.no_grad():\n            batch_acc = []\n            batch_loss = []\n            for batch_idx, (images, labels) in enumerate(self.ldr_test):\n                images, labels = images.to(self.device), labels.to(self.device)\n                #---------forward prop-------------\n                fx = net(images)\n                \n                # calculate loss\n                loss = self.loss_func(fx, labels)\n                # calculate accuracy\n                acc = calculate_accuracy(fx, labels)\n                                 \n                batch_loss.append(loss.item())\n                batch_acc.append(acc.item())\n            \n            prGreen('Client{} Test =>                     \\tLoss: {:.4f} \\tAcc: {:.3f}'.format(self.idx, loss.item(), acc.item()))\n            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n            epoch_acc.append(sum(batch_acc)/len(batch_acc))\n        return sum(epoch_loss) / len(epoch_loss), sum(epoch_acc) / len(epoch_acc)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.062054Z","iopub.execute_input":"2024-05-03T22:43:58.062498Z","iopub.status.idle":"2024-05-03T22:43:58.081597Z","shell.execute_reply.started":"2024-05-03T22:43:58.062472Z","shell.execute_reply":"2024-05-03T22:43:58.080608Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n#                         Data loading \n#============================================================================= \ndf = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\nprint(df.head())\n\nlesion_type = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\n\n# merging both folders of HAM1000 dataset -- part1 and part2 -- into a single directory\nimageid_path = {os.path.splitext(os.path.basename(x))[0]: x\n                for x in glob(os.path.join(\"/kaggle/input/skin-cancer-mnist-ham10000\", '*', '*.jpg'))}\n\n\n#print(\"path---------------------------------------\", imageid_path.get)\ndf['path'] = df['image_id'].map(imageid_path.get)\ndf['cell_type'] = df['dx'].map(lesion_type.get)\ndf['target'] = pd.Categorical(df['cell_type']).codes\nprint(df['cell_type'].value_counts())\nprint(df['target'].value_counts())\n# print(imageid_path)\n# print(df['path'])","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.082692Z","iopub.execute_input":"2024-05-03T22:43:58.082962Z","iopub.status.idle":"2024-05-03T22:43:58.274175Z","shell.execute_reply.started":"2024-05-03T22:43:58.082938Z","shell.execute_reply":"2024-05-03T22:43:58.273292Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"     lesion_id      image_id   dx dx_type   age   sex localization\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\ncell_type\nMelanocytic nevi                  6705\nMelanoma                          1113\nBenign keratosis-like lesions     1099\nBasal cell carcinoma               514\nActinic keratoses                  327\nVascular lesions                   142\nDermatofibroma                     115\nName: count, dtype: int64\ntarget\n4    6705\n5    1113\n2    1099\n1     514\n0     327\n6     142\n3     115\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"#==============================================================\n# Custom dataset prepration in Pytorch format\nclass SkinData(Dataset):\n    def __init__(self, df, transform = None):\n        \n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n        \n        return len(self.df)\n    \n    def __getitem__(self, index):\n        \n        X = Image.open(self.df['path'][index]).resize((64, 64))\n        y = torch.tensor(int(self.df['target'][index]))\n        \n        if self.transform:\n            X = self.transform(X)\n        \n        return X, y","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.276463Z","iopub.execute_input":"2024-05-03T22:43:58.276755Z","iopub.status.idle":"2024-05-03T22:43:58.283833Z","shell.execute_reply.started":"2024-05-03T22:43:58.276730Z","shell.execute_reply":"2024-05-03T22:43:58.282752Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#=====================================================================================================\n# dataset_iid() will create a dictionary to collect the indices of the data samples randomly for each client\n# IID HAM10000 datasets will be created based on this\ndef dataset_iid(dataset, num_users):\n    \n    num_items = int(len(dataset)/num_users)\n    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n    for i in range(num_users):\n        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n        all_idxs = list(set(all_idxs) - dict_users[i])\n    return dict_users    ","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.285073Z","iopub.execute_input":"2024-05-03T22:43:58.285365Z","iopub.status.idle":"2024-05-03T22:43:58.293949Z","shell.execute_reply.started":"2024-05-03T22:43:58.285339Z","shell.execute_reply":"2024-05-03T22:43:58.292978Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n# Train-test split  \ntrain, test = train_test_split(df, test_size = 0.2)\n\ntrain = train.reset_index()\ntest = test.reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.294930Z","iopub.execute_input":"2024-05-03T22:43:58.295197Z","iopub.status.idle":"2024-05-03T22:43:58.314072Z","shell.execute_reply.started":"2024-05-03T22:43:58.295173Z","shell.execute_reply":"2024-05-03T22:43:58.313087Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n#                         Data preprocessing\n#=============================================================================  \n# Data preprocessing: Transformation \nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transforms = transforms.Compose([transforms.RandomHorizontalFlip(), \n                        transforms.RandomVerticalFlip(),\n                        transforms.Pad(3),\n                        transforms.RandomRotation(10),\n                        transforms.CenterCrop(64),\n                        transforms.ToTensor(), \n                        transforms.Normalize(mean = mean, std = std)\n                        ])\n    \ntest_transforms = transforms.Compose([\n                        transforms.Pad(3),\n                        transforms.CenterCrop(64),\n                        transforms.ToTensor(), \n                        transforms.Normalize(mean = mean, std = std)\n                        ])    \n\n# With augmentation\ndataset_train = SkinData(train, transform = train_transforms)\ndataset_test = SkinData(test, transform = test_transforms)\n \n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.315379Z","iopub.execute_input":"2024-05-03T22:43:58.315747Z","iopub.status.idle":"2024-05-03T22:43:58.324532Z","shell.execute_reply.started":"2024-05-03T22:43:58.315718Z","shell.execute_reply":"2024-05-03T22:43:58.323442Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#-----------------------------------------------\ndict_users = dataset_iid(dataset_train, num_users)\ndict_users_test = dataset_iid(dataset_test, num_users)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.325663Z","iopub.execute_input":"2024-05-03T22:43:58.325980Z","iopub.status.idle":"2024-05-03T22:43:58.345891Z","shell.execute_reply.started":"2024-05-03T22:43:58.325953Z","shell.execute_reply":"2024-05-03T22:43:58.344916Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#====================================================================================================\n#                               Server Side Program\n#====================================================================================================\ndef calculate_accuracy(fx, y):\n    preds = fx.max(1, keepdim=True)[1]\n    correct = preds.eq(y.view_as(preds)).sum()\n    acc = 100.00 *correct.float()/preds.shape[0]\n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.347079Z","iopub.execute_input":"2024-05-03T22:43:58.347426Z","iopub.status.idle":"2024-05-03T22:43:58.357347Z","shell.execute_reply.started":"2024-05-03T22:43:58.347375Z","shell.execute_reply":"2024-05-03T22:43:58.356434Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model try2 \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\n\nclass ResNet18(nn.Module):\n    def __init__(self, block, layers, num_classes=1000):\n        super(ResNet18, self).__init__()\n        self.inplanes = 64\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Use AdaptiveAvgPool2d to ensure consistent output size\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\nnet_glob = ResNet18(BasicBlock, [2, 2, 2, 2], 7)  # Assuming 7 classes\nif torch.cuda.device_count() > 1:\n    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n    net_glob = nn.DataParallel(net_glob)  # Utilize multiple GPUs if available\n\nnet_glob.to(device)\nprint(net_glob)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.721136Z","iopub.execute_input":"2024-05-03T22:43:58.721442Z","iopub.status.idle":"2024-05-03T22:43:58.967630Z","shell.execute_reply.started":"2024-05-03T22:43:58.721416Z","shell.execute_reply":"2024-05-03T22:43:58.966323Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"We use 2 GPUs\nDataParallel(\n  (module): ResNet18(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=7, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#===========================================================================================\n# Federated averaging: FedAvg\ndef FedAvg(w):\n    w_avg = copy.deepcopy(w[0])\n    for k in w_avg.keys():\n        for i in range(1, len(w)):\n            w_avg[k] += w[i][k]\n        w_avg[k] = torch.div(w_avg[k], len(w))\n    return w_avg","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.969188Z","iopub.execute_input":"2024-05-03T22:43:58.969606Z","iopub.status.idle":"2024-05-03T22:43:58.976887Z","shell.execute_reply.started":"2024-05-03T22:43:58.969563Z","shell.execute_reply":"2024-05-03T22:43:58.975874Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#====================================================\nnet_glob.train()\n# copy weights\nw_glob = net_glob.state_dict()\n\nloss_train_collect = []\nacc_train_collect = []\nloss_test_collect = []\nacc_test_collect = []\n\nfor iter in range(epochs):\n    w_locals, loss_locals_train, acc_locals_train, loss_locals_test, acc_locals_test = [], [], [], [], []\n    m = max(int(frac * num_users), 1)\n    idxs_users = np.random.choice(range(num_users), m, replace = False)\n    \n    # Training/Testing simulation\n    for idx in idxs_users: # each client\n        local = LocalUpdate(idx, lr, device, dataset_train = dataset_train, dataset_test = dataset_test, idxs = dict_users[idx], idxs_test = dict_users_test[idx])\n        # Training ------------------\n        w, loss_train, acc_train = local.train(net = copy.deepcopy(net_glob).to(device))\n        w_locals.append(copy.deepcopy(w))\n        loss_locals_train.append(copy.deepcopy(loss_train))\n        acc_locals_train.append(copy.deepcopy(acc_train))\n        # Testing -------------------\n        loss_test, acc_test = local.evaluate(net = copy.deepcopy(net_glob).to(device))\n        loss_locals_test.append(copy.deepcopy(loss_test))\n        acc_locals_test.append(copy.deepcopy(acc_test))\n        \n        \n    \n    # Federation process\n    w_glob = FedAvg(w_locals)\n    print(\"------------------------------------------------\")\n    print(\"------ Federation process at Server-Side -------\")\n    print(\"------------------------------------------------\")\n    \n    # update global model --- copy weight to net_glob -- distributed the model to all users\n    net_glob.load_state_dict(w_glob)\n    \n    # Train/Test accuracy\n    acc_avg_train = sum(acc_locals_train) / len(acc_locals_train)\n    acc_train_collect.append(acc_avg_train)\n    acc_avg_test = sum(acc_locals_test) / len(acc_locals_test)\n    acc_test_collect.append(acc_avg_test)\n    \n    # Train/Test loss\n    loss_avg_train = sum(loss_locals_train) / len(loss_locals_train)\n    loss_train_collect.append(loss_avg_train)\n    loss_avg_test = sum(loss_locals_test) / len(loss_locals_test)\n    loss_test_collect.append(loss_avg_test)\n    \n    \n    print('------------------- SERVER ----------------------------------------------')\n    print('Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(iter, acc_avg_train, loss_avg_train))\n    print('Test:  Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(iter, acc_avg_test, loss_avg_test))\n    print('-------------------------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:43:58.978610Z","iopub.execute_input":"2024-05-03T22:43:58.979302Z","iopub.status.idle":"2024-05-03T22:59:04.660861Z","shell.execute_reply.started":"2024-05-03T22:43:58.979266Z","shell.execute_reply":"2024-05-03T22:59:04.659721Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 53.030 \tLoss: 1.4778\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 2.0846 \tAcc: 3.472\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 63.636 \tLoss: 1.2390\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 2.1241 \tAcc: 0.000\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 65.152 \tLoss: 1.1810\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 2.1285 \tAcc: 0.000\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 60.606 \tLoss: 1.3311\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 2.1175 \tAcc: 1.389\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 60.606 \tLoss: 1.2927\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 2.0931 \tAcc: 1.389\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   0, Avg Accuracy 32.944 | Avg Loss 1.677\nTest:  Round   0, Avg Accuracy 1.406 | Avg Loss 2.109\n-------------------------------------------------------------------------\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 77.273 \tLoss: 0.8356\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 1.6316 \tAcc: 68.750\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 77.273 \tLoss: 0.6903\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 1.6991 \tAcc: 59.722\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 71.212 \tLoss: 0.8973\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 1.6644 \tAcc: 62.500\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 68.182 \tLoss: 0.9729\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 1.6631 \tAcc: 69.444\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 74.242 \tLoss: 0.7848\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 1.6394 \tAcc: 65.972\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   1, Avg Accuracy 68.667 | Avg Loss 1.000\nTest:  Round   1, Avg Accuracy 65.217 | Avg Loss 1.657\n-------------------------------------------------------------------------\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 75.758 \tLoss: 0.7227\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 1.0967 \tAcc: 72.222\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 80.303 \tLoss: 0.6647\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 1.2167 \tAcc: 64.583\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 68.182 \tLoss: 0.8559\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 1.1598 \tAcc: 65.972\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 74.242 \tLoss: 0.7152\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 1.1101 \tAcc: 70.139\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 65.152 \tLoss: 0.9456\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 1.2028 \tAcc: 68.056\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   2, Avg Accuracy 69.452 | Avg Loss 0.883\nTest:  Round   2, Avg Accuracy 66.480 | Avg Loss 1.189\n-------------------------------------------------------------------------\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 62.121 \tLoss: 1.0169\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 0.9522 \tAcc: 68.750\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 71.212 \tLoss: 0.7767\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 0.9216 \tAcc: 70.833\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 69.697 \tLoss: 1.0163\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 1.1422 \tAcc: 59.722\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 60.606 \tLoss: 1.1509\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 1.0129 \tAcc: 69.444\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 66.667 \tLoss: 1.0503\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 1.0588 \tAcc: 65.278\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   3, Avg Accuracy 69.828 | Avg Loss 0.864\nTest:  Round   3, Avg Accuracy 66.684 | Avg Loss 1.021\n-------------------------------------------------------------------------\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 65.152 \tLoss: 0.8655\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 1.1191 \tAcc: 63.194\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 63.636 \tLoss: 0.9600\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 0.8705 \tAcc: 68.750\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 74.242 \tLoss: 0.7387\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 0.8830 \tAcc: 70.833\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 77.273 \tLoss: 0.7385\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 0.8515 \tAcc: 69.444\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 65.152 \tLoss: 0.9014\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 0.8539 \tAcc: 71.528\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   4, Avg Accuracy 70.551 | Avg Loss 0.818\nTest:  Round   4, Avg Accuracy 68.320 | Avg Loss 0.927\n-------------------------------------------------------------------------\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 75.758 \tLoss: 0.7826\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 0.8133 \tAcc: 70.139\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 69.697 \tLoss: 0.6977\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 0.8077 \tAcc: 71.528\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 65.152 \tLoss: 0.7996\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 0.8623 \tAcc: 70.833\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 66.667 \tLoss: 0.9320\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 0.6984 \tAcc: 76.389\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 80.303 \tLoss: 0.6388\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 0.8311 \tAcc: 72.222\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   5, Avg Accuracy 71.757 | Avg Loss 0.785\nTest:  Round   5, Avg Accuracy 70.135 | Avg Loss 0.849\n-------------------------------------------------------------------------\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 66.667 \tLoss: 1.0539\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 0.7354 \tAcc: 75.694\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 68.182 \tLoss: 1.0200\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 0.8464 \tAcc: 67.361\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 71.212 \tLoss: 0.7766\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 0.7468 \tAcc: 72.917\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 74.242 \tLoss: 0.7883\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 0.8042 \tAcc: 68.750\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 78.788 \tLoss: 0.6230\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 0.8540 \tAcc: 70.139\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   6, Avg Accuracy 71.677 | Avg Loss 0.792\nTest:  Round   6, Avg Accuracy 70.017 | Avg Loss 0.825\n-------------------------------------------------------------------------\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 75.758 \tLoss: 0.6433\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 0.8271 \tAcc: 68.056\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 68.182 \tLoss: 0.8977\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 0.7115 \tAcc: 76.389\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 66.667 \tLoss: 0.9114\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 0.8676 \tAcc: 69.444\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 62.121 \tLoss: 1.0581\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 0.5951 \tAcc: 78.472\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 71.212 \tLoss: 0.7960\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 0.7882 \tAcc: 70.833\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   7, Avg Accuracy 71.970 | Avg Loss 0.770\nTest:  Round   7, Avg Accuracy 71.163 | Avg Loss 0.780\n-------------------------------------------------------------------------\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 77.273 \tLoss: 0.6169\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 0.6766 \tAcc: 75.000\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 74.242 \tLoss: 0.6985\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 0.7076 \tAcc: 74.306\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 75.758 \tLoss: 0.6799\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 0.7506 \tAcc: 73.611\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 68.182 \tLoss: 0.8705\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 0.8384 \tAcc: 68.056\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 72.727 \tLoss: 0.7494\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 0.7676 \tAcc: 71.528\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   8, Avg Accuracy 72.986 | Avg Loss 0.746\nTest:  Round   8, Avg Accuracy 71.797 | Avg Loss 0.763\n-------------------------------------------------------------------------\n\u001b[91m Client4 Train => Local Epoch: 0  \tAcc: 80.303 \tLoss: 0.5624\u001b[00m\n\u001b[92m Client4 Test =>                     \tLoss: 0.7276 \tAcc: 73.611\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0  \tAcc: 66.667 \tLoss: 0.8343\u001b[00m\n\u001b[92m Client1 Test =>                     \tLoss: 0.8144 \tAcc: 68.750\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0  \tAcc: 75.758 \tLoss: 0.5904\u001b[00m\n\u001b[92m Client2 Test =>                     \tLoss: 0.7095 \tAcc: 72.222\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0  \tAcc: 77.273 \tLoss: 0.6549\u001b[00m\n\u001b[92m Client3 Test =>                     \tLoss: 0.8124 \tAcc: 69.444\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0  \tAcc: 71.212 \tLoss: 0.8029\u001b[00m\n\u001b[92m Client0 Test =>                     \tLoss: 0.7353 \tAcc: 74.306\u001b[00m\n------------------------------------------------\n------ Federation process at Server-Side -------\n------------------------------------------------\n------------------- SERVER ----------------------------------------------\nTrain: Round   9, Avg Accuracy 73.151 | Avg Loss 0.728\nTest:  Round   9, Avg Accuracy 72.044 | Avg Loss 0.748\n-------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"#===================================================================================     \n\nprint(\"Training and Evaluation completed!\")    \n\n#===============================================================================","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:59:04.663651Z","iopub.execute_input":"2024-05-03T22:59:04.664018Z","iopub.status.idle":"2024-05-03T22:59:04.669560Z","shell.execute_reply.started":"2024-05-03T22:59:04.663985Z","shell.execute_reply":"2024-05-03T22:59:04.668703Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Training and Evaluation completed!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save output data to .excel file (we use for comparision plots)\nround_process = [i for i in range(1, len(acc_train_collect)+1)]\ndf = DataFrame({'round': round_process,'acc_train':acc_train_collect, 'acc_test':acc_test_collect})     \nfile_name = program+\".xlsx\"    \ndf.to_excel(file_name, sheet_name= \"v1_test\", index = False)     \n\n#=============================================================================\n#                         Program Completed\n#============================================================================= \n","metadata":{"execution":{"iopub.status.busy":"2024-05-03T22:59:04.670860Z","iopub.execute_input":"2024-05-03T22:59:04.671160Z","iopub.status.idle":"2024-05-03T22:59:05.144470Z","shell.execute_reply.started":"2024-05-03T22:59:04.671135Z","shell.execute_reply":"2024-05-03T22:59:05.143705Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}