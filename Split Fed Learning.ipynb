{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n# Split learning: ResNet18 on HAM10000\n# HAM10000 dataset: Tschandl, P.: The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions (2018), doi:10.7910/DVN/DBW86T\n\n# We have three versions of our implementations\n# Version1: without using socket and no DP+PixelDP\n# Version2: with using socket but no DP+PixelDP\n# Version3: without using socket but with DP+PixelDP\n\n# This program is Version1: Single program simulation \n# ============================================================================\nimport torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\nimport math\nimport os.path\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom glob import glob \nfrom pandas import DataFrame\nimport random\nimport numpy as np\nimport os\n\n\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport copy\n\n\nSEED = 1234\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.backends.cudnn.deterministic = True\n    print(torch.cuda.get_device_name(0))    \n\n#===================================================================  \nprogram = \"SL ResNet18 on HAM10000\"\nprint(f\"---------{program}----------\")              # this is to identify the program in the slurm outputs files\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# To print in color -------test/train of the client side\ndef prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk)) \ndef prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk))     \n\n#===================================================================  \n# No. of users\nnum_users = 5\nepochs = 10\nfrac = 1   # participation of clients; if 1 then 100% clients participate in SL\nlr = 0.0001\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:06.370791Z","iopub.execute_input":"2024-05-04T07:31:06.371270Z","iopub.status.idle":"2024-05-04T07:31:06.384242Z","shell.execute_reply.started":"2024-05-04T07:31:06.371235Z","shell.execute_reply":"2024-05-04T07:31:06.383205Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Tesla T4\n---------SL ResNet18 on HAM10000----------\n","output_type":"stream"}]},{"cell_type":"code","source":"#=====================================================================================================\n#                           Client-side Model definition\n#=====================================================================================================\n# Model at client side\nclass ResNet18_client_side(nn.Module):\n    def __init__(self):\n        super(ResNet18_client_side, self).__init__()\n        self.layer1 = nn.Sequential (\n                nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n                nn.BatchNorm2d(64),\n                nn.ReLU (inplace = True),\n                nn.MaxPool2d(kernel_size = 3, stride = 2, padding =1),\n            )\n        self.layer2 = nn.Sequential  (\n                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1, bias = False),\n                nn.BatchNorm2d(64),\n#                 nn.ReLU (inplace = True),\n                nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n                nn.BatchNorm2d(64),              \n            )\n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        \n        \n    def forward(self, x):\n        resudial1 = F.relu(self.layer1(x))\n        out1 = self.layer2(resudial1)\n        out1 = out1 + resudial1 # adding the resudial inputs -- downsampling not required in this layer\n        residual2 = F.relu(out1)\n        return residual2\n \n \n           \n\nnet_glob_client = ResNet18_client_side()\nif torch.cuda.device_count() > 1:\n    print(\"We use\",torch.cuda.device_count(), \"GPUs\")\n    net_glob_client = nn.DataParallel(net_glob_client)   # to use the multiple GPUs; later we can change this to CPUs only \n\nnet_glob_client.to(device)\nprint(net_glob_client)     \n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:06.558412Z","iopub.execute_input":"2024-05-04T07:31:06.559738Z","iopub.status.idle":"2024-05-04T07:31:06.580484Z","shell.execute_reply.started":"2024-05-04T07:31:06.559696Z","shell.execute_reply":"2024-05-04T07:31:06.579347Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"We use 2 GPUs\nDataParallel(\n  (module): ResNet18_client_side(\n    (layer1): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    )\n    (layer2): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# #=====================================================================================================\n# #                           Server-side Model definition\n# #=====================================================================================================\n# # Model at server side\n# class Baseblock(nn.Module):\n#     expansion = 1\n#     def __init__(self, input_planes, planes, stride = 1, dim_change = None):\n#         super(Baseblock, self).__init__()\n#         self.conv1 = nn.Conv2d(input_planes, planes, stride =  stride, kernel_size = 3, padding = 1)\n#         self.bn1 = nn.BatchNorm2d(planes)\n#         self.conv2 = nn.Conv2d(planes, planes, stride = 1, kernel_size = 3, padding = 1)\n#         self.bn2 = nn.BatchNorm2d(planes)\n#         self.dim_change = dim_change\n        \n#     def forward(self, x):\n#         res = x\n#         output = F.relu(self.bn1(self.conv1(x)))\n#         output = self.bn2(self.conv2(output))\n        \n#         if self.dim_change is not None:\n#             res =self.dim_change(res)\n            \n#         output += res\n#         output = F.relu(output)\n        \n#         return output\n\n\n# class ResNet18_server_side(nn.Module):\n#     def __init__(self, block, num_layers, classes):\n#         super(ResNet18_server_side, self).__init__()\n#         self.input_planes = 64\n#         self.layer3 = nn.Sequential (\n#                 nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n#                 nn.BatchNorm2d(64),\n#                 nn.ReLU (inplace = True),\n#                 nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1),\n#                 nn.BatchNorm2d(64),       \n#                 )   \n        \n#         self.layer4 = self._layer(block, 128, num_layers[0], stride = 2)\n#         self.layer5 = self._layer(block, 256, num_layers[1], stride = 2)\n#         self.layer6 = self._layer(block, 512, num_layers[2], stride = 2)\n#         self. averagePool = nn.AvgPool2d(kernel_size = 7, stride = 1)\n#         self.fc = nn.Linear(512 * block.expansion, classes)\n        \n#         for m in self.modules():\n#             if isinstance(m, nn.Conv2d):\n#                 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n#                 m.weight.data.normal_(0, math.sqrt(2. / n))\n#             elif isinstance(m, nn.BatchNorm2d):\n#                 m.weight.data.fill_(1)\n#                 m.bias.data.zero_()\n        \n        \n#     def _layer(self, block, planes, num_layers, stride = 2):\n#         dim_change = None\n#         if stride != 1 or planes != self.input_planes * block.expansion:\n#             dim_change = nn.Sequential(nn.Conv2d(self.input_planes, planes*block.expansion, kernel_size = 1, stride = stride),\n#                                        nn.BatchNorm2d(planes*block.expansion))\n#         netLayers = []\n#         netLayers.append(block(self.input_planes, planes, stride = stride, dim_change = dim_change))\n#         self.input_planes = planes * block.expansion\n#         for i in range(1, num_layers):\n#             netLayers.append(block(self.input_planes, planes))\n#             self.input_planes = planes * block.expansion\n            \n#         return nn.Sequential(*netLayers)\n        \n    \n#     def forward(self, x):\n#         out2 = self.layer3(x)\n#         out2 = out2 + x          # adding the resudial inputs -- downsampling not required in this layer\n#         x3 = F.relu(out2)\n        \n#         x4 = self. layer4(x3)\n#         x5 = self.layer5(x4)\n#         x6 = self.layer6(x5)\n        \n#         x7 = F.avg_pool2d(x6, 7)\n#         x8 = x7.view(x7.size(0), -1) \n#         y_hat =self.fc(x8)\n        \n#         return y_hat\n\n# net_glob_server = ResNet18_server_side(Baseblock, [2,2,2], 7) #7 is my numbr of classes\n# if torch.cuda.device_count() > 1:\n#     print(\"We use\",torch.cuda.device_count(), \"GPUs\")\n#     net_glob_server = nn.DataParallel(net_glob_server)   # to use the multiple GPUs \n\n# net_glob_server.to(device)\n# print(net_glob_server)      \n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:06.790640Z","iopub.execute_input":"2024-05-04T07:31:06.791407Z","iopub.status.idle":"2024-05-04T07:31:06.799847Z","shell.execute_reply.started":"2024-05-04T07:31:06.791374Z","shell.execute_reply":"2024-05-04T07:31:06.798491Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n# import math\n\nclass ResNet18_server_side(nn.Module):\n    def __init__(self, block, num_layers, classes):\n        super(ResNet18_server_side, self).__init__()\n        self.input_planes = 64\n        self.layer3 = nn.Sequential (\n                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm2d(64),\n                nn.ReLU(inplace=True),\n                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm2d(64),       \n                )   \n        \n        self.layer4 = self._layer(block, 128, num_layers[0], stride=2)\n        self.layer5 = self._layer(block, 256, num_layers[1], stride=2)\n        self.layer6 = self._layer(block, 512, num_layers[2], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Use AdaptiveAvgPool2d to specify output size\n        self.fc = nn.Linear(512 * block.expansion, classes)\n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        \n    def _layer(self, block, planes, num_layers, stride=2):\n        dim_change = None\n        if stride != 1 or planes != self.input_planes * block.expansion:\n            dim_change = nn.Sequential(nn.Conv2d(self.input_planes, planes*block.expansion, kernel_size=1, stride=stride),\n                                       nn.BatchNorm2d(planes*block.expansion))\n        netLayers = []\n        netLayers.append(block(self.input_planes, planes, stride=stride, dim_change=dim_change))\n        self.input_planes = planes * block.expansion\n        for i in range(1, num_layers):\n            netLayers.append(block(self.input_planes, planes))\n            self.input_planes = planes * block.expansion\n            \n        return nn.Sequential(*netLayers)\n        \n    \n    def forward(self, x):\n        out2 = self.layer3(x)\n        out2 = out2 + x  # Adding the residual inputs; downsampling not required in this layer\n        x3 = F.relu(out2)\n        \n        x4 = self.layer4(x3)\n        x5 = self.layer5(x4)\n        x6 = self.layer6(x5)\n        \n        x7 = self.avgpool(x6)\n        x8 = x7.view(x7.size(0), -1) \n        y_hat = self.fc(x8)\n        \n        return y_hat\n\nnet_glob_server = ResNet18_server_side(Baseblock, [2,2,2], 7)  # 7 is the number of classes\nif torch.cuda.device_count() > 1:\n    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n    net_glob_server = nn.DataParallel(net_glob_server)   # To use multiple GPUs \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnet_glob_server.to(device)\nprint(net_glob_server)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:06.989910Z","iopub.execute_input":"2024-05-04T07:31:06.990369Z","iopub.status.idle":"2024-05-04T07:31:07.255885Z","shell.execute_reply.started":"2024-05-04T07:31:06.990339Z","shell.execute_reply":"2024-05-04T07:31:07.254804Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"We use 2 GPUs\nDataParallel(\n  (module): ResNet18_server_side(\n    (layer3): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (layer4): Sequential(\n      (0): Baseblock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dim_change): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Baseblock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer5): Sequential(\n      (0): Baseblock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dim_change): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Baseblock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer6): Sequential(\n      (0): Baseblock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dim_change): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Baseblock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=7, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#===================================================================================\n# For Server Side Loss and Accuracy \nloss_train_collect = []\nacc_train_collect = []\nloss_test_collect = []\nacc_test_collect = []\nbatch_acc_train = []\nbatch_loss_train = []\nbatch_acc_test = []\nbatch_loss_test = []\n\ncriterion = nn.CrossEntropyLoss()\ncount1 = 0\ncount2 = 0","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:07.257621Z","iopub.execute_input":"2024-05-04T07:31:07.257960Z","iopub.status.idle":"2024-05-04T07:31:07.264265Z","shell.execute_reply.started":"2024-05-04T07:31:07.257917Z","shell.execute_reply":"2024-05-04T07:31:07.263253Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#====================================================================================================\n#                                  Server Side Program\n#====================================================================================================\ndef calculate_accuracy(fx, y):\n    preds = fx.max(1, keepdim=True)[1]\n    correct = preds.eq(y.view_as(preds)).sum()\n    acc = 100.00 *correct.float()/preds.shape[0]\n    return acc\n\n# to print train - test together in each round-- these are made global\nacc_avg_all_user_train = 0\nloss_avg_all_user_train = 0\nloss_train_collect_user = []\nacc_train_collect_user = []\nloss_test_collect_user = []\nacc_test_collect_user = []\n\n\n#client idx collector\nidx_collect = []\nl_epoch_check = False\nfed_check = False\n\n# Server-side function associated with Training \ndef train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch):\n    global net_glob_server, criterion, device, batch_acc_train, batch_loss_train, l_epoch_check, fed_check\n    global loss_train_collect, acc_train_collect, count1, acc_avg_all_user_train, loss_avg_all_user_train, idx_collect\n    global loss_train_collect_user, acc_train_collect_user\n    \n    net_glob_server.train()\n    optimizer_server = torch.optim.Adam(net_glob_server.parameters(), lr = lr)\n\n    \n    # train and update\n    optimizer_server.zero_grad()\n    \n    fx_client = fx_client.to(device)\n    y = y.to(device)\n    \n    #---------forward prop-------------\n    fx_server = net_glob_server(fx_client)\n    \n    # calculate loss\n    loss = criterion(fx_server, y)\n    # calculate accuracy\n    acc = calculate_accuracy(fx_server, y)\n    \n    #--------backward prop--------------\n    loss.backward()\n    dfx_client = fx_client.grad.clone().detach()\n    optimizer_server.step()\n    \n    batch_loss_train.append(loss.item())\n    batch_acc_train.append(acc.item())\n    \n    # server-side model net_glob_server is global so it is updated automatically in each pass to this function\n        # count1: to track the completion of the local batch associated with one client\n    count1 += 1\n    if count1 == len_batch:\n        acc_avg_train = sum(batch_acc_train)/len(batch_acc_train)           # it has accuracy for one batch\n        loss_avg_train = sum(batch_loss_train)/len(batch_loss_train)\n        \n        batch_acc_train = []\n        batch_loss_train = []\n        count1 = 0\n        \n        prRed('Client{} Train => Local Epoch: {} \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, l_epoch_count, acc_avg_train, loss_avg_train))\n        \n                \n        # If one local epoch is completed, after this a new client will come\n        if l_epoch_count == l_epoch-1:\n            \n            l_epoch_check = True                # for evaluate_server function - to check local epoch has hitted \n                       \n            # we store the last accuracy in the last batch of the epoch and it is not the average of all local epochs\n            # this is because we work on the last trained model and its accuracy (not earlier cases)\n            \n            #print(\"accuracy = \", acc_avg_train)\n            acc_avg_train_all = acc_avg_train\n            loss_avg_train_all = loss_avg_train\n                        \n            # accumulate accuracy and loss for each new user\n            loss_train_collect_user.append(loss_avg_train_all)\n            acc_train_collect_user.append(acc_avg_train_all)\n            \n            # collect the id of each new user                        \n            if idx not in idx_collect:\n                idx_collect.append(idx) \n                #print(idx_collect)\n        \n        # This is to check if all users are served for one round --------------------\n        if len(idx_collect) == num_users:\n            fed_check = True                                                  # for evaluate_server function  - to check fed check has hitted\n            # all users served for one round ------------------------- output print and update is done in evaluate_server()\n            # for nicer display \n                        \n            idx_collect = []\n            \n            acc_avg_all_user_train = sum(acc_train_collect_user)/len(acc_train_collect_user)\n            loss_avg_all_user_train = sum(loss_train_collect_user)/len(loss_train_collect_user)\n            \n            loss_train_collect.append(loss_avg_all_user_train)\n            acc_train_collect.append(acc_avg_all_user_train)\n            \n            acc_train_collect_user = []\n            loss_train_collect_user = []\n            \n    # send gradients to the client               \n    return dfx_client\n\n# Server-side functions associated with Testing\ndef evaluate_server(fx_client, y, idx, len_batch, ell):\n    global net_glob_server, criterion, batch_acc_test, batch_loss_test\n    global loss_test_collect, acc_test_collect, count2, num_users, acc_avg_train_all, loss_avg_train_all, l_epoch_check, fed_check\n    global loss_test_collect_user, acc_test_collect_user, acc_avg_all_user_train, loss_avg_all_user_train\n    \n    net_glob_server.eval()\n  \n    with torch.no_grad():\n        fx_client = fx_client.to(device)\n        y = y.to(device) \n        #---------forward prop-------------\n        fx_server = net_glob_server(fx_client)\n        \n        # calculate loss\n        loss = criterion(fx_server, y)\n        # calculate accuracy\n        acc = calculate_accuracy(fx_server, y)\n        \n        \n        batch_loss_test.append(loss.item())\n        batch_acc_test.append(acc.item())\n        \n               \n        count2 += 1\n        if count2 == len_batch:\n            acc_avg_test = sum(batch_acc_test)/len(batch_acc_test)\n            loss_avg_test = sum(batch_loss_test)/len(batch_loss_test)\n            \n            batch_acc_test = []\n            batch_loss_test = []\n            count2 = 0\n            \n            prGreen('Client{} Test =>                   \\tAcc: {:.3f} \\tLoss: {:.4f}'.format(idx, acc_avg_test, loss_avg_test))\n            \n            # if a local epoch is completed   \n            if l_epoch_check:\n                l_epoch_check = False\n                \n                # Store the last accuracy and loss\n                acc_avg_test_all = acc_avg_test\n                loss_avg_test_all = loss_avg_test\n                        \n                loss_test_collect_user.append(loss_avg_test_all)\n                acc_test_collect_user.append(acc_avg_test_all)\n                \n            # if all users are served for one round ----------                    \n            if fed_check:\n                fed_check = False\n                                \n                acc_avg_all_user = sum(acc_test_collect_user)/len(acc_test_collect_user)\n                loss_avg_all_user = sum(loss_test_collect_user)/len(loss_test_collect_user)\n            \n                loss_test_collect.append(loss_avg_all_user)\n                acc_test_collect.append(acc_avg_all_user)\n                acc_test_collect_user = []\n                loss_test_collect_user= []\n                              \n                print(\"====================== SERVER V1==========================\")\n                print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user_train, loss_avg_all_user_train))\n                print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user, loss_avg_all_user))\n                print(\"==========================================================\")\n         \n    return \n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:07.354259Z","iopub.execute_input":"2024-05-04T07:31:07.354651Z","iopub.status.idle":"2024-05-04T07:31:07.383116Z","shell.execute_reply.started":"2024-05-04T07:31:07.354621Z","shell.execute_reply":"2024-05-04T07:31:07.381932Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#==============================================================================================================\n#                                       Clients Side Program\n#==============================================================================================================\nclass DatasetSplit(Dataset):\n    def __init__(self, dataset, idxs):\n        self.dataset = dataset\n        self.idxs = list(idxs)\n\n    def __len__(self):\n        return len(self.idxs)\n\n    def __getitem__(self, item):\n        image, label = self.dataset[self.idxs[item]]\n        return image, label\n\n# Client-side functions associated with Training and Testing\nclass Client(object):\n    def __init__(self, net_client_model, idx, lr, device, dataset_train = None, dataset_test = None, idxs = None, idxs_test = None):\n        self.idx = idx\n        self.device = device\n        self.lr = lr\n        self.local_ep = 1 \n        #self.selected_clients = []\n        self.ldr_train = DataLoader(DatasetSplit(dataset_train, idxs), batch_size = 256*4, shuffle = True)\n        self.ldr_test = DataLoader(DatasetSplit(dataset_test, idxs_test), batch_size = 256*4, shuffle = True)\n        \n\n    def train(self, net):\n        net.train()\n        optimizer_client = torch.optim.Adam(net.parameters(), lr = self.lr) \n        \n        for iter in range(self.local_ep):\n            len_batch = len(self.ldr_train)\n            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n                images, labels = images.to(self.device), labels.to(self.device)\n                optimizer_client.zero_grad()\n                #---------forward prop-------------\n                fx = net(images)\n                client_fx = fx.clone().detach().requires_grad_(True)\n                \n                # Sending activations to server and receiving gradients from server\n                dfx = train_server(client_fx, labels, iter, self.local_ep, self.idx, len_batch)\n                \n                #--------backward prop -------------\n                fx.backward(dfx)\n                optimizer_client.step()\n                            \n            \n            #prRed('Client{} Train => Epoch: {}'.format(self.idx, ell))\n           \n        return net.state_dict() \n    \n    def evaluate(self, net, ell):\n        net.eval()\n           \n        with torch.no_grad():\n            len_batch = len(self.ldr_test)\n            for batch_idx, (images, labels) in enumerate(self.ldr_test):\n                images, labels = images.to(self.device), labels.to(self.device)\n                #---------forward prop-------------\n                fx = net(images)\n                \n                # Sending activations to server \n                evaluate_server(fx, labels, self.idx, len_batch, ell)\n            \n            #prRed('Client{} Test => Epoch: {}'.format(self.idx, ell))\n            \n        return          ","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:07.594973Z","iopub.execute_input":"2024-05-04T07:31:07.595708Z","iopub.status.idle":"2024-05-04T07:31:07.612694Z","shell.execute_reply.started":"2024-05-04T07:31:07.595667Z","shell.execute_reply":"2024-05-04T07:31:07.611621Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#=====================================================================================================\n# dataset_iid() will create a dictionary to collect the indices of the data samples randomly for each client\n# IID HAM10000 datasets will be created based on this\ndef dataset_iid(dataset, num_users):\n    \n    num_items = int(len(dataset)/num_users)\n    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n    for i in range(num_users):\n        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace = False))\n        all_idxs = list(set(all_idxs) - dict_users[i])\n    return dict_users    \n            ","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:07.744453Z","iopub.execute_input":"2024-05-04T07:31:07.745261Z","iopub.status.idle":"2024-05-04T07:31:07.751950Z","shell.execute_reply.started":"2024-05-04T07:31:07.745227Z","shell.execute_reply":"2024-05-04T07:31:07.750881Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n#                         Data loading \n#============================================================================= \ndf = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\nprint(df.head())\n\nlesion_type = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\n\n# merging both folders of HAM1000 dataset -- part1 and part2 -- into a single directory\nimageid_path = {os.path.splitext(os.path.basename(x))[0]: x\n                for x in glob(os.path.join(\"/kaggle/input/skin-cancer-mnist-ham10000\", '*', '*.jpg'))}\n\n\n#print(\"path---------------------------------------\", imageid_path.get)\ndf['path'] = df['image_id'].map(imageid_path.get)\ndf['cell_type'] = df['dx'].map(lesion_type.get)\ndf['target'] = pd.Categorical(df['cell_type']).codes\nprint(df['cell_type'].value_counts())\nprint(df['target'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:07.915491Z","iopub.execute_input":"2024-05-04T07:31:07.915874Z","iopub.status.idle":"2024-05-04T07:31:08.121324Z","shell.execute_reply.started":"2024-05-04T07:31:07.915843Z","shell.execute_reply":"2024-05-04T07:31:08.120223Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"     lesion_id      image_id   dx dx_type   age   sex localization\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\ncell_type\nMelanocytic nevi                  6705\nMelanoma                          1113\nBenign keratosis-like lesions     1099\nBasal cell carcinoma               514\nActinic keratoses                  327\nVascular lesions                   142\nDermatofibroma                     115\nName: count, dtype: int64\ntarget\n4    6705\n5    1113\n2    1099\n1     514\n0     327\n6     142\n3     115\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"#==============================================================\n# Custom dataset prepration in Pytorch format\nclass SkinData(Dataset):\n    def __init__(self, df, transform = None):\n        self.df = df\n        self.transform = transform\n        \n    def __len__(self):\n       \n        return len(self.df)\n    \n    def __getitem__(self, index):\n                \n        X = Image.open(self.df['path'][index]).resize((64, 64))\n        y = torch.tensor(int(self.df['target'][index]))\n        \n        if self.transform:\n            X = self.transform(X)\n        \n        return X, y\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:08.122988Z","iopub.execute_input":"2024-05-04T07:31:08.123283Z","iopub.status.idle":"2024-05-04T07:31:08.130893Z","shell.execute_reply.started":"2024-05-04T07:31:08.123259Z","shell.execute_reply":"2024-05-04T07:31:08.129840Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n# Train-test split      \ntrain, test = train_test_split(df, test_size = 0.2)\n\ntrain = train.reset_index()\ntest = test.reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:08.247507Z","iopub.execute_input":"2024-05-04T07:31:08.247878Z","iopub.status.idle":"2024-05-04T07:31:08.264397Z","shell.execute_reply.started":"2024-05-04T07:31:08.247847Z","shell.execute_reply":"2024-05-04T07:31:08.263280Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#=============================================================================\n#                         Data preprocessing\n#=============================================================================  \n# Data preprocessing: Transformation \nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transforms = transforms.Compose([transforms.RandomHorizontalFlip(), \n                        transforms.RandomVerticalFlip(),\n                        transforms.Pad(3),\n                        transforms.RandomRotation(10),\n                        transforms.CenterCrop(64),\n                        transforms.ToTensor(), \n                        transforms.Normalize(mean = mean, std = std)\n                        ])\n    \ntest_transforms = transforms.Compose([\n                        transforms.Pad(3),\n                        transforms.CenterCrop(64),\n                        transforms.ToTensor(), \n                        transforms.Normalize(mean = mean, std = std)\n                        ])    \n\n\n# With augmentation\ndataset_train = SkinData(train, transform = train_transforms)\ndataset_test = SkinData(test, transform = test_transforms)\n\n#----------------------------------------------------------------\ndict_users = dataset_iid(dataset_train, num_users)\ndict_users_test = dataset_iid(dataset_test, num_users)\n\n\n#net_glob_client.train()\n# this epoch is global epoch, also known as rounds\nfor iter in range(epochs):\n    m = max(int(frac * num_users), 1)\n    idxs_users = np.random.choice(range(num_users), m, replace = False)\n\n    # Sequential training/testing among clients      \n    for idx in idxs_users:\n        local = Client(net_glob_client, idx, lr, device, dataset_train = dataset_train, dataset_test = dataset_test, idxs = dict_users[idx], idxs_test = dict_users_test[idx])\n        # Training ------------------\n        w_client = local.train(net = copy.deepcopy(net_glob_client).to(device))\n              \n        # Testing -------------------\n        local.evaluate(net = copy.deepcopy(net_glob_client).to(device), ell= iter)\n        \n        # copy weight to net_glob_client -- use to update the client-side model of the next client to be trained\n        net_glob_client.load_state_dict(w_client)\n   \n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:31:08.436098Z","iopub.execute_input":"2024-05-04T07:31:08.436494Z","iopub.status.idle":"2024-05-04T07:49:41.889864Z","shell.execute_reply.started":"2024-05-04T07:31:08.436465Z","shell.execute_reply":"2024-05-04T07:49:41.888779Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 10.152 \tLoss: 2.1376\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 59.750 \tLoss: 1.7912\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 51.695 \tLoss: 1.5571\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 61.250 \tLoss: 1.8193\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 67.053 \tLoss: 1.1689\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 64.250 \tLoss: 1.7200\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.481 \tLoss: 1.0045\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 69.500 \tLoss: 1.4966\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 68.109 \tLoss: 0.9452\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 61.250 \tLoss: 1.4277\u001b[00m\n====================== SERVER V1==========================\n Train: Round   0, Avg Accuracy 53.298 | Avg Loss 1.363\n Test: Round   0, Avg Accuracy 63.200 | Avg Loss 1.651\n==========================================================\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 69.811 \tLoss: 0.8806\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 69.250 \tLoss: 1.1760\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 71.548 \tLoss: 0.8559\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 65.500 \tLoss: 1.1425\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.324 \tLoss: 0.8574\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 70.250 \tLoss: 1.0171\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 70.752 \tLoss: 0.8114\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 65.000 \tLoss: 1.0730\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 71.737 \tLoss: 0.8143\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 67.750 \tLoss: 0.9408\u001b[00m\n====================== SERVER V1==========================\n Train: Round   1, Avg Accuracy 71.034 | Avg Loss 0.844\n Test: Round   1, Avg Accuracy 67.550 | Avg Loss 1.070\n==========================================================\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 71.156 \tLoss: 0.8044\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 69.750 \tLoss: 0.8898\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 72.962 \tLoss: 0.7688\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 65.750 \tLoss: 0.9292\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 71.511 \tLoss: 0.8032\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 70.500 \tLoss: 0.8375\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 71.467 \tLoss: 0.7822\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 66.000 \tLoss: 1.0151\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 70.954 \tLoss: 0.7736\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 67.750 \tLoss: 0.8599\u001b[00m\n====================== SERVER V1==========================\n Train: Round   2, Avg Accuracy 71.610 | Avg Loss 0.786\n Test: Round   2, Avg Accuracy 67.950 | Avg Loss 0.906\n==========================================================\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 72.895 \tLoss: 0.7446\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 64.250 \tLoss: 0.9517\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 71.780 \tLoss: 0.7570\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 71.250 \tLoss: 0.8061\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 73.754 \tLoss: 0.7398\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 68.250 \tLoss: 0.8083\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 73.210 \tLoss: 0.7315\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 71.500 \tLoss: 0.8344\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 73.016 \tLoss: 0.7547\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 72.500 \tLoss: 0.7253\u001b[00m\n====================== SERVER V1==========================\n Train: Round   3, Avg Accuracy 72.931 | Avg Loss 0.746\n Test: Round   3, Avg Accuracy 69.550 | Avg Loss 0.825\n==========================================================\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 73.867 \tLoss: 0.6976\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 68.250 \tLoss: 0.8741\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 75.347 \tLoss: 0.6896\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 68.500 \tLoss: 0.8091\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 74.067 \tLoss: 0.6942\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 72.250 \tLoss: 0.7496\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 74.284 \tLoss: 0.6903\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 73.750 \tLoss: 0.7302\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 74.604 \tLoss: 0.7225\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 75.250 \tLoss: 0.6775\u001b[00m\n====================== SERVER V1==========================\n Train: Round   4, Avg Accuracy 74.434 | Avg Loss 0.699\n Test: Round   4, Avg Accuracy 71.600 | Avg Loss 0.768\n==========================================================\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 74.332 \tLoss: 0.6937\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 76.250 \tLoss: 0.6669\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.773 \tLoss: 0.6683\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 72.750 \tLoss: 0.7162\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.915 \tLoss: 0.6875\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 70.500 \tLoss: 0.6993\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.822 \tLoss: 0.6664\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 75.000 \tLoss: 0.7190\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 75.463 \tLoss: 0.6988\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 73.750 \tLoss: 0.7131\u001b[00m\n====================== SERVER V1==========================\n Train: Round   5, Avg Accuracy 75.261 | Avg Loss 0.683\n Test: Round   5, Avg Accuracy 73.650 | Avg Loss 0.703\n==========================================================\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 76.140 \tLoss: 0.6728\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 75.500 \tLoss: 0.6857\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.806 \tLoss: 0.6734\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 71.750 \tLoss: 0.6890\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 74.658 \tLoss: 0.6690\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 70.750 \tLoss: 0.7142\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 75.431 \tLoss: 0.6460\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 73.000 \tLoss: 0.6882\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 75.664 \tLoss: 0.6553\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 72.250 \tLoss: 0.6913\u001b[00m\n====================== SERVER V1==========================\n Train: Round   6, Avg Accuracy 75.340 | Avg Loss 0.663\n Test: Round   6, Avg Accuracy 72.650 | Avg Loss 0.694\n==========================================================\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 74.720 \tLoss: 0.6601\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 72.000 \tLoss: 0.6881\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 77.207 \tLoss: 0.6488\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 74.000 \tLoss: 0.6959\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 77.514 \tLoss: 0.6163\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 74.500 \tLoss: 0.6755\u001b[00m\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.031 \tLoss: 0.6478\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 75.500 \tLoss: 0.6674\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 76.821 \tLoss: 0.6476\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 74.250 \tLoss: 0.6860\u001b[00m\n====================== SERVER V1==========================\n Train: Round   7, Avg Accuracy 76.659 | Avg Loss 0.644\n Test: Round   7, Avg Accuracy 74.050 | Avg Loss 0.683\n==========================================================\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 77.246 \tLoss: 0.6300\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 74.500 \tLoss: 0.6778\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 75.820 \tLoss: 0.6429\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 75.000 \tLoss: 0.6971\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 78.471 \tLoss: 0.6153\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 73.750 \tLoss: 0.7022\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.561 \tLoss: 0.6315\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 72.250 \tLoss: 0.6966\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 77.098 \tLoss: 0.6085\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 71.750 \tLoss: 0.7416\u001b[00m\n====================== SERVER V1==========================\n Train: Round   8, Avg Accuracy 77.039 | Avg Loss 0.626\n Test: Round   8, Avg Accuracy 73.450 | Avg Loss 0.703\n==========================================================\n\u001b[91m Client4 Train => Local Epoch: 0 \tAcc: 76.621 \tLoss: 0.6253\u001b[00m\n\u001b[92m Client4 Test =>                   \tAcc: 74.000 \tLoss: 0.7026\u001b[00m\n\u001b[91m Client1 Train => Local Epoch: 0 \tAcc: 77.965 \tLoss: 0.6027\u001b[00m\n\u001b[92m Client1 Test =>                   \tAcc: 73.500 \tLoss: 0.6817\u001b[00m\n\u001b[91m Client2 Train => Local Epoch: 0 \tAcc: 76.537 \tLoss: 0.6408\u001b[00m\n\u001b[92m Client2 Test =>                   \tAcc: 72.000 \tLoss: 0.6823\u001b[00m\n\u001b[91m Client3 Train => Local Epoch: 0 \tAcc: 76.599 \tLoss: 0.6107\u001b[00m\n\u001b[92m Client3 Test =>                   \tAcc: 75.000 \tLoss: 0.6338\u001b[00m\n\u001b[91m Client0 Train => Local Epoch: 0 \tAcc: 77.229 \tLoss: 0.6199\u001b[00m\n\u001b[92m Client0 Test =>                   \tAcc: 77.250 \tLoss: 0.6515\u001b[00m\n====================== SERVER V1==========================\n Train: Round   9, Avg Accuracy 76.990 | Avg Loss 0.620\n Test: Round   9, Avg Accuracy 74.350 | Avg Loss 0.670\n==========================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"#===================================================================================     \n\nprint(\"Training and Evaluation completed!\")    \n\n#==================================================================","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:49:41.891955Z","iopub.execute_input":"2024-05-04T07:49:41.892301Z","iopub.status.idle":"2024-05-04T07:49:41.897779Z","shell.execute_reply.started":"2024-05-04T07:49:41.892270Z","shell.execute_reply":"2024-05-04T07:49:41.896777Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Training and Evaluation completed!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save output data to .excel file (we use for comparision plots)\nround_process = [i for i in range(1, len(acc_train_collect)+1)]\ndf = DataFrame({'round': round_process,'acc_train':acc_train_collect, 'acc_test':acc_test_collect})     \nfile_name = program+\".xlsx\"    \ndf.to_excel(file_name, sheet_name= \"v1_test\", index = False)     \n\n#=============================================================================\n#                         Program Completed\n#============================================================================= \n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T07:49:41.899040Z","iopub.execute_input":"2024-05-04T07:49:41.899339Z","iopub.status.idle":"2024-05-04T07:49:42.420068Z","shell.execute_reply.started":"2024-05-04T07:49:41.899313Z","shell.execute_reply":"2024-05-04T07:49:42.419153Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}